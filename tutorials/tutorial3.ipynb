{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TP d'Introduction à l'Économétrie\n",
    "## Modèle Linéaire Simple\n",
    "\n",
    "Ce TP reprend les concepts fondamentaux du modèle linéaire simple présentés dans le cours.\n",
    "\n",
    "Nous allons explorer les méthodes d'estimation (MCO et maximum de vraisemblance), les hypothèses du modèle, les tests statistiques et l'interprétation des résultats."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Importation des bibliothèques nécessaires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy.stats as stats\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.graphics.gofplots import ProbPlot\n",
    "\n",
    "# Configuration pour de meilleurs graphiques\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "plt.rcParams['font.size'] = 14\n",
    "np.random.seed(0)  # Pour reproduire les résultats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Génération de données simulées\n",
    "\n",
    "Nous allons simuler un modèle linéaire simple de la forme : $Y_i = \\alpha + \\beta X_i + u_i$\n",
    "\n",
    "Où :\n",
    "- $\\alpha$ est la constante (l'ordonnée à l'origine)\n",
    "- $\\beta$ est le coefficient de la variable explicative\n",
    "- $u_i$ est le terme d'erreur qui suit une loi normale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paramètres du modèle\n",
    "alpha_vrai = 10  # Vraie valeur de alpha\n",
    "beta_vrai = 2    # Vraie valeur de beta\n",
    "sigma_u = 3      # Écart-type du terme d'erreur\n",
    "n = 100          # Nombre d'observations\n",
    "\n",
    "# Génération de la variable explicative X\n",
    "X = np.random.uniform(0, 10, n)\n",
    "\n",
    "# Génération du terme d'erreur u (suivant une loi normale centrée de variance sigma_u²)\n",
    "u = np.random.normal(0, sigma_u, n)\n",
    "\n",
    "# Génération de la variable dépendante Y selon le modèle\n",
    "Y = alpha_vrai + beta_vrai * X + u\n",
    "\n",
    "# Création d'un DataFrame pour stocker les données\n",
    "df = pd.DataFrame({\n",
    "    'X': X,\n",
    "    'Y': Y,\n",
    "    'u': u  # On garde les erreurs pour vérification ultérieure\n",
    "})\n",
    "\n",
    "# Affichage des premières lignes du DataFrame\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Visualisation des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(X, Y, alpha=0.7)\n",
    "plt.plot(X, alpha_vrai + beta_vrai * X, 'r-', label='Vraie relation : Y = {} + {}X'.format(alpha_vrai, beta_vrai))\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('Y')\n",
    "plt.title('Relation entre X et Y avec le vrai modèle')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Estimation par la méthode des Moindres Carrés Ordinaires (MCO)\n",
    "\n",
    "Rappel des formules des estimateurs MCO :\n",
    "\n",
    "$$\\hat{\\beta} = \\frac{\\sum_{i=1}^{n}(X_i - \\bar{X})(Y_i - \\bar{Y})}{\\sum_{i=1}^{n}(X_i - \\bar{X})^2}$$\n",
    "\n",
    "$$\\hat{\\alpha} = \\bar{Y} - \\hat{\\beta}\\bar{X}$$\n",
    "\n",
    "Nous allons implémenter ces formules manuellement puis comparer avec l'estimateur de statsmodels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcul manuel des estimateurs MCO\n",
    "X_mean = np.mean(X)\n",
    "Y_mean = np.mean(Y)\n",
    "\n",
    "# Calcul de beta\n",
    "numerator = np.sum((X - X_mean) * (Y - Y_mean))\n",
    "denominator = np.sum((X - X_mean)**2)\n",
    "beta_hat = numerator / denominator\n",
    "\n",
    "# Calcul de alpha\n",
    "alpha_hat = Y_mean - beta_hat * X_mean\n",
    "\n",
    "print(f\"Estimateur MCO manuel pour α: {alpha_hat:.4f}\")\n",
    "print(f\"Estimateur MCO manuel pour β: {beta_hat:.4f}\")\n",
    "print(f\"Valeurs réelles: α = {alpha_vrai}, β = {beta_vrai}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utilisation de statsmodels pour l'estimation MCO\n",
    "X_sm = sm.add_constant(X)  # Ajoute une colonne de 1 pour la constante\n",
    "model = sm.OLS(Y, X_sm)    # Ordinary Least Squares\n",
    "results = model.fit()\n",
    "\n",
    "# Affichage du résumé des résultats\n",
    "print(results.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Calcul et interprétation des résidus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcul des valeurs prédites\n",
    "Y_pred = alpha_hat + beta_hat * X\n",
    "\n",
    "# Calcul des résidus\n",
    "residus = Y - Y_pred\n",
    "\n",
    "# Ajout des résidus et valeurs prédites au DataFrame\n",
    "df['Y_pred'] = Y_pred\n",
    "df['residus'] = residus\n",
    "\n",
    "# Estimation de la variance des erreurs\n",
    "sigma_u_hat = np.sqrt(np.sum(residus**2) / (n - 2))\n",
    "\n",
    "print(f\"Estimation de l'écart-type des erreurs: {sigma_u_hat:.4f}\")\n",
    "print(f\"Vraie valeur de l'écart-type des erreurs: {sigma_u:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisation des résidus\n",
    "plt.figure(figsize=(16, 6))\n",
    "\n",
    "# Premier graphique: résidus en fonction de X\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.scatter(X, residus, alpha=0.7)\n",
    "plt.axhline(y=0, color='r', linestyle='-')\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('Résidus')\n",
    "plt.title('Résidus en fonction de X')\n",
    "plt.grid(True)\n",
    "\n",
    "# Deuxième graphique: histogramme des résidus\n",
    "plt.subplot(1, 2, 2)\n",
    "sns.histplot(residus, kde=True)\n",
    "plt.xlabel('Résidus')\n",
    "plt.title('Distribution des résidus')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Vérification des hypothèses du modèle linéaire simple\n",
    "\n",
    "Rappel des hypothèses :\n",
    "1. La distribution de l'erreur u est indépendante de X\n",
    "2. L'erreur est centrée et de variance constante (homoscédasticité)\n",
    "3. Les coefficients α et β sont constants\n",
    "4. Les résidus suivent une loi normale\n",
    "5. Non-autocorrélation des résidus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diagnostic graphique des résidus\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "# Graphique 1: Résidus vs Valeurs prédites\n",
    "axes[0, 0].scatter(Y_pred, residus, alpha=0.7)\n",
    "axes[0, 0].axhline(y=0, color='r', linestyle='-')\n",
    "axes[0, 0].set_xlabel('Valeurs prédites')\n",
    "axes[0, 0].set_ylabel('Résidus')\n",
    "axes[0, 0].set_title('Résidus vs Valeurs prédites (homoscédasticité)')\n",
    "axes[0, 0].grid(True)\n",
    "\n",
    "# Graphique 2: QQ-plot pour tester la normalité\n",
    "qq_plot = ProbPlot(residus)\n",
    "qq_plot.qqplot(line='s', ax=axes[0, 1])\n",
    "axes[0, 1].set_title('QQ-Plot des résidus (normalité)')\n",
    "\n",
    "# Graphique 3: Résidus vs ordre (autocorrélation)\n",
    "axes[1, 0].plot(range(len(residus)), residus, marker='o', linestyle='none', alpha=0.7)\n",
    "axes[1, 0].axhline(y=0, color='r', linestyle='-')\n",
    "axes[1, 0].set_xlabel('Ordre des observations')\n",
    "axes[1, 0].set_ylabel('Résidus')\n",
    "axes[1, 0].set_title('Résidus vs Ordre (autocorrélation)')\n",
    "axes[1, 0].grid(True)\n",
    "\n",
    "# Graphique 4: Distribution des résidus standardisés\n",
    "standardized_residuals = residus / np.std(residus)\n",
    "sns.histplot(standardized_residuals, kde=True, ax=axes[1, 1])\n",
    "axes[1, 1].set_xlabel('Résidus standardisés')\n",
    "axes[1, 1].set_title('Distribution des résidus standardisés')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test de normalité des résidus (Shapiro-Wilk)\n",
    "shapiro_test = stats.shapiro(residus)\n",
    "print(f\"Test de Shapiro-Wilk pour la normalité des résidus:\")\n",
    "print(f\"Statistique W: {shapiro_test[0]:.4f}\")\n",
    "print(f\"p-value: {shapiro_test[1]:.4f}\")\n",
    "print(f\"Conclusion: {'Résidus normaux' if shapiro_test[1] > 0.05 else 'Résidus non normaux'}\")\n",
    "\n",
    "# Test d'homoscédasticité (Breusch-Pagan)\n",
    "bp_test = sm.stats.diagnostic.het_breuschpagan(residus, results.model.exog)\n",
    "print(\"\\nTest de Breusch-Pagan pour l'homoscédasticité:\")\n",
    "print(f\"Statistique LM: {bp_test[0]:.4f}\")\n",
    "print(f\"p-value: {bp_test[1]:.4f}\")\n",
    "print(f\"Conclusion: {'Homoscédasticité' if bp_test[1] > 0.05 else 'Hétéroscédasticité'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Analyse de la variance et qualité de l'ajustement (R²)\n",
    "\n",
    "Rappel de la décomposition de la variance totale :\n",
    "\n",
    "$$\\sum_{i=1}^{n}(Y_i - \\bar{Y})^2 = \\sum_{i=1}^{n}(\\hat{Y}_i - \\bar{Y})^2 + \\sum_{i=1}^{n}(Y_i - \\hat{Y}_i)^2$$\n",
    "\n",
    "$$SCT = SCE + SCR$$\n",
    "\n",
    "Et le coefficient de détermination :\n",
    "\n",
    "$$R^2 = \\frac{SCE}{SCT} = 1 - \\frac{SCR}{SCT}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcul de la somme des carrés totale (SCT)\n",
    "SCT = np.sum((Y - Y_mean)**2)\n",
    "\n",
    "# Calcul de la somme des carrés expliquée (SCE)\n",
    "SCE = np.sum((Y_pred - Y_mean)**2)\n",
    "\n",
    "# Calcul de la somme des carrés résiduelle (SCR)\n",
    "SCR = np.sum((Y - Y_pred)**2)\n",
    "\n",
    "# Calcul du R²\n",
    "R2 = SCE / SCT\n",
    "# Vérification: R² = 1 - SCR/SCT\n",
    "R2_verif = 1 - SCR / SCT\n",
    "\n",
    "print(f\"Somme des carrés totale (SCT): {SCT:.4f}\")\n",
    "print(f\"Somme des carrés expliquée (SCE): {SCE:.4f}\")\n",
    "print(f\"Somme des carrés résiduelle (SCR): {SCR:.4f}\")\n",
    "print(f\"Vérification: SCT = SCE + SCR -> {SCT:.4f} = {SCE:.4f} + {SCR:.4f} -> {SCE + SCR:.4f}\")\n",
    "print(f\"\\nR² calculé manuellement: {R2:.4f}\")\n",
    "print(f\"R² calculé par vérification: {R2_verif:.4f}\")\n",
    "print(f\"R² fourni par statsmodels: {results.rsquared:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisation de la décomposition de la variance\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.scatter(X, Y, alpha=0.7, label='Observations')\n",
    "plt.plot(X, Y_pred, 'r-', linewidth=2, label=f'Régression: Y = {alpha_hat:.4f} + {beta_hat:.4f}X')\n",
    "plt.plot([X_mean, X_mean], [0, Y_mean], 'k--', alpha=0.5)\n",
    "plt.axhline(y=Y_mean, color='g', linestyle='--', alpha=0.5, label=f'Moyenne de Y: {Y_mean:.4f}')\n",
    "\n",
    "# Ajouter quelques lignes pour illustrer la décomposition de la variance\n",
    "for i in range(0, n, 10):  # Afficher seulement quelques lignes pour clarté\n",
    "    plt.plot([X[i], X[i]], [Y[i], Y_pred[i]], 'b-', alpha=0.3)  # SCR\n",
    "    plt.plot([X[i], X[i]], [Y_pred[i], Y_mean], 'g-', alpha=0.3)  # SCE\n",
    "\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('Y')\n",
    "plt.title(f'Régression linéaire avec décomposition de la variance (R² = {R2:.4f})')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Tests statistiques sur les coefficients\n",
    "\n",
    "Nous allons tester les hypothèses : $H_0: \\beta = 0$ vs $H_1: \\beta \\neq 0$\n",
    "\n",
    "Rappel : sous les hypothèses du modèle linéaire simple :\n",
    "\n",
    "$$\\frac{\\hat{\\beta} - \\beta}{\\sqrt{s^2 C_\\beta}} \\sim T(n-2)$$\n",
    "\n",
    "Où $C_\\beta = \\frac{1}{n\\sum_{i=1}^{n}(X_i - \\bar{X})^2}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcul de l'écart-type de beta\n",
    "C_beta = 1 / (n * np.sum((X - X_mean)**2))\n",
    "se_beta = np.sqrt(sigma_u_hat**2 * C_beta)\n",
    "\n",
    "# Statistique de test pour H0: beta = 0\n",
    "t_stat = beta_hat / se_beta\n",
    "\n",
    "# Valeur critique et p-value\n",
    "dof = n - 2  # degrés de liberté\n",
    "p_value = 2 * (1 - stats.t.cdf(abs(t_stat), dof))  # test bilatéral\n",
    "\n",
    "# Intervalle de confiance à 95%\n",
    "t_crit = stats.t.ppf(0.975, dof)  # quantile à 97.5% (test bilatéral à 5%)\n",
    "ci_lower = beta_hat - t_crit * se_beta\n",
    "ci_upper = beta_hat + t_crit * se_beta\n",
    "\n",
    "print(f\"Test de significativité de β:\")\n",
    "print(f\"H0: β = 0 vs H1: β ≠ 0\")\n",
    "print(f\"Estimateur de β: {beta_hat:.4f}\")\n",
    "print(f\"Écart-type de β: {se_beta:.4f}\")\n",
    "print(f\"Statistique t: {t_stat:.4f}\")\n",
    "print(f\"p-value: {p_value:.6f}\")\n",
    "print(f\"Conclusion: {'Rejet de H0' if p_value < 0.05 else 'Non-rejet de H0'} au seuil de 5%\")\n",
    "print(f\"\\nIntervalle de confiance à 95% pour β: [{ci_lower:.4f}, {ci_upper:.4f}]\")\n",
    "print(f\"La vraie valeur de β ({beta_vrai}) est-elle dans l'intervalle? {'Oui' if ci_lower <= beta_vrai <= ci_upper else 'Non'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Prévisions avec le modèle estimé\n",
    "\n",
    "Maintenant que nous avons estimé notre modèle, nous pouvons l'utiliser pour faire des prévisions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nouvelle valeur de X pour la prévision\n",
    "X_new = 15  # Une valeur en dehors de la plage des données\n",
    "\n",
    "# Prévision ponctuelle\n",
    "Y_pred_new = alpha_hat + beta_hat * X_new\n",
    "\n",
    "# Intervalle de prévision à 95%\n",
    "# Formule: Y_pred ± t_{n-2, 0.975} * s * sqrt(1 + 1/n + (X_new - X̄)²/Σ(X_i - X̄)²)\n",
    "prediction_variance = sigma_u_hat**2 * (1 + 1/n + ((X_new - X_mean)**2) / np.sum((X - X_mean)**2))\n",
    "prediction_se = np.sqrt(prediction_variance)\n",
    "prediction_margin = t_crit * prediction_se\n",
    "\n",
    "pred_lower = Y_pred_new - prediction_margin\n",
    "pred_upper = Y_pred_new + prediction_margin\n",
    "\n",
    "print(f\"Prévision pour X = {X_new}:\")\n",
    "print(f\"Valeur prédite: {Y_pred_new:.4f}\")\n",
    "print(f\"Intervalle de prévision à 95%: [{pred_lower:.4f}, {pred_upper:.4f}]\")\n",
    "\n",
    "# Visualisation\n",
    "X_range = np.linspace(0, 16, 100)\n",
    "Y_range_pred = alpha_hat + beta_hat * X_range\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.scatter(X, Y, alpha=0.7, label='Observations')\n",
    "plt.plot(X_range, Y_range_pred, 'r-', linewidth=2, label=f'Régression: Y = {alpha_hat:.4f} + {beta_hat:.4f}X')\n",
    "plt.scatter(X_new, Y_pred_new, color='green', s=100, marker='X', label=f'Prévision pour X = {X_new}')\n",
    "\n",
    "# Ajout de l'intervalle de prévision\n",
    "plt.fill_between(X_range, \n",
    "                 alpha_hat + beta_hat * X_range - t_crit * sigma_u_hat * np.sqrt(1 + 1/n + ((X_range - X_mean)**2) / np.sum((X - X_mean)**2)),\n",
    "                 alpha_hat + beta_hat * X_range + t_crit * sigma_u_hat * np.sqrt(1 + 1/n + ((X_range - X_mean)**2) / np.sum((X - X_mean)**2)),\n",
    "                 color='gray', alpha=0.2, label='Intervalle de prévision à 95%')\n",
    "\n",
    "plt.vlines(X_new, pred_lower, pred_upper, color='green', linestyle='--', alpha=0.7)\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('Y')\n",
    "plt.title('Régression linéaire avec prévision')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Différents types de modèles et interprétation des coefficients\n",
    "\n",
    "Comme indiqué dans le cours, il existe différentes formes de modèles linéaires selon la transformation appliquée aux variables. Nous allons explorer quatre types de modèles :\n",
    "\n",
    "1. lin-lin: $Y = \\alpha + \\beta X + u$\n",
    "2. log-lin: $\\log(Y) = \\alpha + \\beta X + u$\n",
    "3. lin-log: $Y = \\alpha + \\beta \\log(X) + u$\n",
    "4. log-log: $\\log(Y) = \\alpha + \\beta \\log(X) + u$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Création de nouvelles variables avec des distributions positives\n",
    "np.random.seed(0)\n",
    "X_pos = np.random.lognormal(0, 0.5, n)  # Distribution log-normale pour assurer X > 0\n",
    "beta_log_lin = 0.05  # Pour log-lin\n",
    "beta_lin_log = 5     # Pour lin-log\n",
    "beta_log_log = 0.8   # Pour log-log\n",
    "\n",
    "# Génération des Y pour les différents modèles\n",
    "Y_lin_lin = 10 + 2 * X_pos + np.random.normal(0, 1, n)\n",
    "Y_log_lin = np.exp(2 + beta_log_lin * X_pos + np.random.normal(0, 0.1, n))\n",
    "Y_lin_log = 5 + beta_lin_log * np.log(X_pos) + np.random.normal(0, 1, n)\n",
    "Y_log_log = np.exp(1 + beta_log_log * np.log(X_pos) + np.random.normal(0, 0.1, n))\n",
    "\n",
    "# Création d'un DataFrame pour ces données\n",
    "df_models = pd.DataFrame({\n",
    "    'X': X_pos,\n",
    "    'Y_lin_lin': Y_lin_lin,\n",
    "    'Y_log_lin': Y_log_lin,\n",
    "    'Y_lin_log': Y_lin_log,\n",
    "    'Y_log_log': Y_log_log,\n",
    "    'log_X': np.log(X_pos),\n",
    "    'log_Y_log_lin': np.log(Y_log_lin),\n",
    "    'log_Y_log_log': np.log(Y_log_log)\n",
    "})\n",
    "\n",
    "# Affichage des premières lignes du DataFrame\n",
    "df_models.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
